{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class MyLogReg():\n",
    "    def __init__(self, n_iter=10, learning_rate=0.1, weights=[], metric=None, reg=None, l1_coef=0, l2_coef=0, sgd_sample=None, random_state=42):\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = weights\n",
    "        self.metric = metric\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.sgd_sample = sgd_sample\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"{self.__class__.__name__} class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
    "\n",
    "\n",
    "    def fit(self, x, y, verbose=False):\n",
    "      random.seed(self.random_state)\n",
    "\n",
    "      self.weights = np.ones(len(x.columns) + 1)\n",
    "      x.insert(0, 'x0', 1)\n",
    "      n = len(y)\n",
    "      for i in range(1, self.n_iter + 1):\n",
    "        x_sample = x\n",
    "        y_sample = y\n",
    "        if self.sgd_sample is not None:\n",
    "            if isinstance(self.sgd_sample, float):\n",
    "                sample_size = max(int(round(self.sgd_sample * x.shape[0])), 1)\n",
    "            else:\n",
    "                sample_size = int(self.sgd_sample)\n",
    "            sample_rows_idx = random.sample(range(x.shape[0]), sample_size)\n",
    "            x_sample = x.iloc[sample_rows_idx]\n",
    "            y_sample = y.iloc[sample_rows_idx]\n",
    "        current_learning_rate = self.learning_rate(i) if callable(self.learning_rate) else self.learning_rate\n",
    "        predict = 1 / (1 + np.exp(-x_sample.dot(self.weights)))\n",
    "        logloss = -1 / n * sum(y * np.log(predict) + (1 - y) * np.log(1 - predict)) + self.calculate_reg()\n",
    "        grad = 1 / len(y_sample) * (self.predict_proba(x_sample) - y_sample).dot(x_sample) + self.calculate_reg_grad()\n",
    "        self.weights -= current_learning_rate * grad\n",
    "        if verbose and i == 0:\n",
    "          self.metric_val = self.get_score(x, y)\n",
    "          print(f'start | loss: {logloss} | {self.metric}: {self.metric_val}')\n",
    "        elif (verbose and i % verbose == 0):\n",
    "          self.metric_val = self.get_score(x, y)\n",
    "          print(f'{i} | loss: {logloss} | {self.metric}: {self.metric_val}')\n",
    "      if not verbose:\n",
    "        self.metric_val = self.get_score(x, y)\n",
    "        \n",
    "\n",
    "    def get_coef(self):\n",
    "      return self.weights.values[1:]\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "      if x.columns[0] != 'x0':\n",
    "          x.insert(0, 'x0', 1)\n",
    "      return 1 / (1 + np.exp(-x.dot(self.weights)))\n",
    "\n",
    "    def predict(self, x):\n",
    "      proba = self.predict_proba(x)\n",
    "      return [1 if p > 0.5 else 0 for p in proba]\n",
    "    \n",
    "    def get_best_score(self):\n",
    "        return self.metric_val\n",
    "    \n",
    "    def get_score(self, x, y):\n",
    "      y_pred = np.round(self.predict_proba(x), 10)\n",
    "      cm = confusion_matrix(y, self.predict(x))\n",
    "      TN, FP, FN, TP = cm.ravel()\n",
    "      precision = TP / (TP + FP)\n",
    "      recall = TP / (TP + FN)\n",
    "      \n",
    "      if self.metric == 'accuracy':\n",
    "        return (TP + TN) / (TP + TN + FP + FN)\n",
    "      elif self.metric == 'precision':\n",
    "        return precision\n",
    "      elif self.metric == 'recall':\n",
    "        return recall\n",
    "      elif self.metric == 'f1':\n",
    "        return 2 * precision * recall / (recall + precision)\n",
    "      elif self.metric == 'roc_auc':       \n",
    "        return roc_auc_score(y_true=y, y_score=self.predict_proba(x))\n",
    "    def calculate_reg(self):\n",
    "      if self.reg == 'l1':\n",
    "        return self.l1_coef * sum(abs(self.weights))\n",
    "      elif self.reg == 'l2':\n",
    "        return self.l2_coef * sum(np.square(self.weights))\n",
    "      elif self.reg == 'elasticnet':\n",
    "        return self.l1_coef * sum(abs(self.weights)) + self.l2_coef * sum(np.square(self.weights))\n",
    "      return 0\n",
    "\n",
    "\n",
    "    def calculate_reg_grad(self):\n",
    "      if self.reg == 'l1':\n",
    "        return self.l1_coef * np.sign(self.weights)\n",
    "      elif self.reg == 'l2':\n",
    "        return self.l2_coef * 2 * self.weights\n",
    "      elif self.reg == 'elasticnet':\n",
    "        return self.l1_coef * np.sign(self.weights) + self.l2_coef * 2 * self.weights\n",
    "      return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 | loss: 2.6812948097440965 | roc_auc: 0.5696102784411138\n",
      "10 | loss: 1.8729518276291253 | roc_auc: 0.6219904879619518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.6219904879619518)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=14, n_informative=10, random_state=42)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "X.columns = [f'x{col + 1}' for col in X.columns]\n",
    "\n",
    "model = MyLogReg(metric='roc_auc')\n",
    "model.fit(X, y, 5)\n",
    "model.get_best_score()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "class MyKNNClf:\n",
    "    def __init__(self, k=3, metric='euclidean', weight='uniform'):\n",
    "        self.weight = weight\n",
    "        self.metric = metric\n",
    "        self.k = k\n",
    "        self.train_size = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X.copy()\n",
    "        self.y = y.copy()\n",
    "        self.train_size = X.shape\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"MyKNNClf class: k={self.k}\"\n",
    "\n",
    "    def predict(self, X_test):\n",
    "            predictions = []\n",
    "            \n",
    "\n",
    "            for i, test_row in X_test.iterrows():\n",
    "                distances = self.calculate_distance(test_row)\n",
    "\n",
    "                sorted_indices = np.argsort(distances)[:self.k]\n",
    "                nearest_labels = self.y.iloc[sorted_indices]\n",
    "                if self.weight == 'uniform':\n",
    "                    counter_dic = Counter(nearest_labels)\n",
    "                    most_common_label = 0 if counter_dic[1] < counter_dic[0] else 1\n",
    "                elif self.weight == 'rank':\n",
    "                    weights = 1 / np.arange(1, self.k + 1)\n",
    "                    class_weight = [0, 0]\n",
    "                    for i, mark in enumerate(nearest_labels):\n",
    "                        class_weight[mark] += weights[i]\n",
    "                    most_common_label = class_weight.index(max(class_weight))\n",
    "                else:\n",
    "                    weights = 1 / distances[sorted_indices]\n",
    "                    class_weight = [0, 0]\n",
    "                    for i, mark in enumerate(nearest_labels):\n",
    "                        class_weight[mark] += weights.values[i]\n",
    "                    most_common_label = class_weight.index(max(class_weight))\n",
    "                \n",
    "                predictions.append(most_common_label)\n",
    "\n",
    "            # print(predictions)\n",
    "            return np.array(predictions)\n",
    "\n",
    "\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        proba = []\n",
    "        for i, test_row in X_test.iterrows():\n",
    "            \n",
    "            distances = self.calculate_distance(test_row)\n",
    "\n",
    "            sorted_indices = np.argsort(distances)[:self.k]\n",
    "            nearest_labels = self.y.iloc[sorted_indices]\n",
    "\n",
    "            if self.weight == 'uniform':\n",
    "                class_weight = sum(nearest_labels == 1) / self.k\n",
    "            elif self.weight == 'rank':\n",
    "                weights = 1 / np.arange(1, self.k + 1)\n",
    "                total_weight = sum(weights)\n",
    "                class_1_weight = 0\n",
    "                for i, mark in enumerate(nearest_labels):\n",
    "                    if mark == 1:\n",
    "                        class_1_weight += weights[i]\n",
    "                class_weight = class_1_weight / total_weight\n",
    "            else:\n",
    "                weights = 1 / distances[sorted_indices]\n",
    "                total_weight = sum(weights)\n",
    "                class_1_weight = 0\n",
    "                for i, mark in enumerate(nearest_labels):\n",
    "                    if mark == 1:\n",
    "                        class_1_weight += weights.values[i]\n",
    "                class_weight = class_1_weight / total_weight\n",
    "\n",
    "            proba.append(class_weight)\n",
    "        \n",
    "        \n",
    "\n",
    "        return np.array(proba)\n",
    "    \n",
    "\n",
    "    def calculate_distance(self, test_row):\n",
    "        if self.metric == 'euclidean':\n",
    "            return np.sqrt(((self.X - test_row) ** 2).sum(axis=1))\n",
    "        elif self.metric == 'chebyshev':\n",
    "            return (abs(self.X - test_row)).max(axis=1)\n",
    "        elif self.metric == 'manhattan':\n",
    "            return (abs(self.X - test_row)).sum(axis=1)\n",
    "        else:\n",
    "            return 1 - (self.X * test_row).sum(axis=1) / (np.sqrt((self.X ** 2).sum(axis=1)) * np.sqrt((test_row ** 2).sum()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKNNReg():\n",
    "    def __init__(self, k=3, metric='euclidean', weight='uniform'):\n",
    "        self.k = k\n",
    "        self.train_size = None\n",
    "        self.metric = metric\n",
    "        self.weight = weight\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"MyKNNReg class: k={self.k}\"\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.train_size = np.shape(x)\n",
    "        self.X = x\n",
    "        self.y = y\n",
    "\n",
    "    def predict(self, x_train):\n",
    "        predictions = []\n",
    "        for _, test_row in x_train.iterrows():\n",
    "            distances = self.calculate_metric(test_row)\n",
    "            nearest_neighbours = distances.nsmallest(self.k).index\n",
    "            target_values = self.y.iloc[nearest_neighbours]\n",
    "\n",
    "            if self.weight == 'uniform':\n",
    "                predict_value = np.average(target_values)\n",
    "            elif self.weight == 'rank':\n",
    "                total_weight = sum(1 / np.array(1, self.k + 1))\n",
    "                weights = (1 / np.arange(1, self.k + 1)) / total_weight\n",
    "                predict_value = weights * target_values\n",
    "            else:\n",
    "                total_weight = sum(1 / distances[target_values.index])\n",
    "                weights = (1 / distances[target_values.index]) / total_weight\n",
    "                predict_value = weights * target_values\n",
    "\n",
    "            predictions.append(predict_value)\n",
    "        return np.array(predictions)\n",
    "    \n",
    "\n",
    "    def calculate_metric(self, test_row):\n",
    "        if self.metric == \"euclidean\":\n",
    "            return np.sqrt(((self.X - test_row) ** 2).sum(axis=1))\n",
    "        elif self.metric == \"chebyshev\":\n",
    "            return (abs(self.X - test_row)).max(axis=1)\n",
    "        elif self.metric == \"manhattan\":\n",
    "            return abs(self.X - test_row).sum(axis=1)\n",
    "        else:\n",
    "            return 1 - (self.X * test_row).sum(axis=1) / (np.sqrt((self.X ** 2).sum(axis=1)) * np.sqrt((test_row ** 2).sum()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=14, n_informative=10, random_state=42)\n",
    "X_train = pd.DataFrame(X)\n",
    "y_train = pd.Series(y)\n",
    "X_train.columns = [f'col_{col}' for col in X_train.columns]\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=14, n_informative=10, random_state=42)\n",
    "X_test = pd.DataFrame(X)\n",
    "y_test = pd.Series(y)\n",
    "X_test.columns = [f'col_{col}' for col in X_test.columns]\n",
    "\n",
    "# Создаем и обучаем модель\n",
    "knn = MyKNNClf(4, 'manhattan', 'distance')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Применяем модель для предсказания классов\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Выводим результат предсказаний\n",
    "print(\"Predictions:\", sum(predictions))\n",
    "\n",
    "proba = knn.predict_proba(X_test)\n",
    "\n",
    "print(\"Proba:\", sum(proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "class MyTreeClf:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, max_leafs=20, bins=None, criterion=\"entropy\"):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs\n",
    "        self.leafs_cnt = 1\n",
    "        self.leafs_sum = 0\n",
    "        self.bins = bins\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"MyTreeClf class: max_depth={self.max_depth}, min_samples_split={self.min_samples_split}, max_leafs={self.max_leafs}\"\n",
    "    \n",
    "\n",
    "    def calculate_entropy(self, y):\n",
    "        value_counts = y.value_counts(normalize=True) \n",
    "        entropy = -np.sum(value_counts * np.log2(value_counts))\n",
    "        return entropy\n",
    "    \n",
    "    def calculate_gini(self, y):\n",
    "        value_counts = y.value_counts(normalize=True)\n",
    "        gini = 1 - np.sum(value_counts ** 2)\n",
    "        return gini\n",
    "      \n",
    "\n",
    "    def calculate_information_gain(self, y, y_left, y_right):\n",
    "        if self.criterion == \"entropy\":\n",
    "            ig = self.calculate_entropy(y) - len(y_left) / len(y) * self.calculate_entropy(y_left) - len(y_right) / len(y) * self.calculate_entropy(y_right)\n",
    "        else:\n",
    "            ig = self.calculate_gini(y) - len(y_left) / len(y) * self.calculate_gini(y_left) - len(y_right) / len(y) * self.calculate_gini(y_right)\n",
    "        return ig\n",
    "    \n",
    "\n",
    "    def get_best_split(self, X, y):\n",
    "        best_ig = -1\n",
    "        best_col = None\n",
    "        best_split_value = None\n",
    "\n",
    "        for col in X.columns:\n",
    "            unique_values = np.sort(X[col].unique())\n",
    "\n",
    "            if self.bins is None or len(unique_values) <= self.bins - 1:\n",
    "                for i in range(1, len(unique_values)):\n",
    "                    split_value = (unique_values[i - 1] + unique_values[i]) / 2\n",
    "\n",
    "                    left_mask = X[col] <= split_value\n",
    "                    right_mask = X[col] > split_value\n",
    "\n",
    "                    y_left, y_right = y[left_mask], y[right_mask]\n",
    "\n",
    "                    if len(y_left) > 0 and len(y_right) > 0:\n",
    "\n",
    "                        ig = self.calculate_information_gain(y, y_left, y_right)\n",
    "\n",
    "                        if ig > best_ig:\n",
    "                            best_ig = ig\n",
    "                            best_col = col\n",
    "                            best_split_value = split_value\n",
    "            else:\n",
    "                hist, bin_edges = np.histogram(X[col], bins=self.bins)\n",
    "                \n",
    "\n",
    "                for i in range(1, len(bin_edges)):\n",
    "                    split_value = bin_edges[i]\n",
    "                    \n",
    "\n",
    "                    left_mask = X[col] <= split_value\n",
    "                    right_mask = X[col] > split_value\n",
    "\n",
    "                    y_left, y_right = y[left_mask], y[right_mask]\n",
    "\n",
    "                    if len(y_left) > 0 and len(y_right) > 0:\n",
    "\n",
    "                        ig = self.calculate_information_gain(y, y_left, y_right)\n",
    "\n",
    "                        if ig > best_ig:\n",
    "                            best_ig = ig\n",
    "                            best_col = col\n",
    "                            best_split_value = split_value\n",
    "\n",
    "        return (best_col, best_split_value, best_ig)\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.build_tree(X, y)\n",
    "    \n",
    "    def build_tree(self, X, y, depth=0, leaf=None):\n",
    "\n",
    "        cnt_dic = Counter(y)\n",
    "        leaf_value = cnt_dic[1] / len(y)\n",
    "        col, split_value, ig = self.get_best_split(X, y)\n",
    "\n",
    "        if (self.leafs_cnt > 1 and self.leafs_cnt >= self.max_leafs) or depth >= self.max_depth or leaf_value == 0 or leaf_value == 1 or len(y) < self.min_samples_split or ig == 0 or split_value is None:\n",
    "            self.leafs_sum += leaf_value\n",
    "            if leaf is None:\n",
    "                return {'leaf': leaf_value}\n",
    "            return {'leaf' + leaf: leaf_value}\n",
    "        \n",
    "        self.leafs_cnt += 1\n",
    "\n",
    "        left_mask = X[col] <= split_value\n",
    "        right_mask = X[col] > split_value\n",
    "\n",
    "        y_left, y_right = y[left_mask], y[right_mask]\n",
    "        X_left, X_right = X[left_mask], X[right_mask]\n",
    "\n",
    "        left_subtree = self.build_tree(X_left, y_left, depth + 1, \"_left\")\n",
    "        right_subtree = self.build_tree(X_right, y_right, depth + 1, \"_right\")\n",
    "\n",
    "        return {\n",
    "            \"feature\": col,\n",
    "            \"split_value\": split_value,\n",
    "            \"left\": left_subtree,\n",
    "            \"right\": right_subtree\n",
    "        }\n",
    "\n",
    "    def print_tree(self, node, depth=0):\n",
    "        if len(node) == 1:\n",
    "            if \"leaf_left\" in node:\n",
    "                print(\" \" * 4 * depth + \"leaf_left = \" + str(node[\"leaf_left\"]))\n",
    "            else:\n",
    "                print(\" \" * 4 * depth + \"leaf_right = \" + str(node[\"leaf_right\"]))\n",
    "            return\n",
    "        print(\" \" * 4 * depth + node[\"feature\"] + \" <= \" + str(node[\"split_value\"]))\n",
    "        self.print_tree(node[\"left\"], depth + 1)\n",
    "        self.print_tree(node[\"right\"], depth + 1)\n",
    "        return\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        return [1 if c > 0.5 else 0 for c in self.predict_proba(X)]\n",
    "    \n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        predictions = []\n",
    "        for i, row in X.iterrows():\n",
    "            p = self.tree\n",
    "            while len(p) != 1:\n",
    "                feature = p[\"feature\"]\n",
    "                split_value = p[\"split_value\"]\n",
    "                if row[feature] <= split_value:\n",
    "                    p = p[\"left\"]\n",
    "                else:\n",
    "                    p = p[\"right\"]\n",
    "            predictions.append(p[\"leaf_left\"] if \"leaf_left\" in p else p[\"leaf_right\"])\n",
    "        return predictions\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance <= 0.7580312500000002\n",
      "    skewness <= 6.2704249999999995\n",
      "        variance <= -0.3773262499999994\n",
      "            curtosis <= 5.774475000000001\n",
      "                leaf_left = 0.9965753424657534\n",
      "                leaf_right = 0.8963414634146342\n",
      "            curtosis <= -0.08158750000000037\n",
      "                leaf_left = 1.0\n",
      "                leaf_right = 0.26153846153846155\n",
      "        variance <= -4.12065875\n",
      "            leaf_left = 0.9736842105263158\n",
      "            leaf_right = 0.0\n",
      "    curtosis <= -4.4146937500000005\n",
      "        leaf_left = 0.7142857142857143\n",
      "        variance <= 1.896305\n",
      "            curtosis <= -1.7564374999999997\n",
      "                leaf_left = 0.6\n",
      "                leaf_right = 0.009259259259259259\n",
      "            variance <= 2.20470625\n",
      "                leaf_left = 0.044444444444444446\n",
      "                leaf_right = 0.0\n",
      "11\n",
      "5.496128895934583\n"
     ]
    }
   ],
   "source": [
    "obj_2 = MyTreeClf(4, 100, 17,16, \"gini\")\n",
    "obj_2.fit(X, y)\n",
    "obj_2.print_tree(obj_2.tree)\n",
    "print(obj_2.leafs_cnt)\n",
    "print(obj_2.leafs_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance <= -0.10864999999999991\n",
      "    leaf_left = 0.8333333333333334\n",
      "    leaf_right = 0.14781491002570693\n",
      "2\n",
      "0.9811482433590403\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('test.txt', header=None)\n",
    "df.columns = ['variance', 'skewness', 'curtosis', 'entropy', 'target']\n",
    "X, y = df.iloc[:,:4], df['target']\n",
    "\n",
    "obj = MyTreeClf(1, 1, 2, 8, \"gini\")\n",
    "obj.fit(X, y)\n",
    "obj.print_tree(obj.tree)\n",
    "print(obj.leafs_cnt)\n",
    "print(obj.leafs_sum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance <= 0.320165\n",
      "    leaf_left = 0.8112633181126332\n",
      "    leaf_right = 0.1076923076923077\n",
      "None\n",
      "3.6216 0.320165\n",
      "Counter({0.1076923076923077: 1372})\n"
     ]
    }
   ],
   "source": [
    "print(obj.print_tree(obj.tree))\n",
    "print(Counter(obj.predict_proba(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       variance  skewness  curtosis  entropy\n",
      "0      3.62160   8.66610   -2.8073 -0.44699\n",
      "1      4.54590   8.16740   -2.4586 -1.46210\n",
      "2      3.86600  -2.63830    1.9242  0.10645\n",
      "3      3.45660   9.52280   -4.0112 -3.59440\n",
      "4      0.32924  -4.45520    4.5718 -0.98880\n",
      "...        ...       ...       ...      ...\n",
      "1367   0.40614   1.34920   -1.4501 -0.55949\n",
      "1368  -1.38870  -4.87730    6.4774  0.34179\n",
      "1369  -3.75030 -13.45860   17.5932 -2.77710\n",
      "1370  -3.56370  -8.38270   12.3930 -1.28230\n",
      "1371  -2.54190  -0.65804    2.6842  1.19520\n",
      "\n",
      "[1372 rows x 4 columns]>\n",
      "variance <= {'feature': 'variance', 'split_value': np.float64(0.320165), 'left': {'feature': 'skewness', 'split_value': np.float64(5.86535), 'left': {'feature': 'curtosis', 'split_value': np.float64(6.21865), 'left': {'leaf_left': 0.9945205479452055}, 'right': {'leaf_right': 0.8397435897435898}}, 'right': {'feature': 'variance', 'split_value': np.float64(-3.4448999999999996), 'left': {'leaf_left': 0.975}, 'right': {'leaf_right': 0.0}}}, 'right': {'leaf_right': 0.1076923076923077}}\n",
      "    skewness <= {'feature': 'skewness', 'split_value': np.float64(5.86535), 'left': {'feature': 'curtosis', 'split_value': np.float64(6.21865), 'left': {'leaf_left': 0.9945205479452055}, 'right': {'leaf_right': 0.8397435897435898}}, 'right': {'feature': 'variance', 'split_value': np.float64(-3.4448999999999996), 'left': {'leaf_left': 0.975}, 'right': {'leaf_right': 0.0}}}\n",
      "        curtosis <= {'feature': 'curtosis', 'split_value': np.float64(6.21865), 'left': {'leaf_left': 0.9945205479452055}, 'right': {'leaf_right': 0.8397435897435898}}\n",
      "            leaf_left = 0.9945205479452055\n",
      "            leaf_right = 0.8397435897435898\n",
      "        variance <= {'feature': 'variance', 'split_value': np.float64(-3.4448999999999996), 'left': {'leaf_left': 0.975}, 'right': {'leaf_right': 0.0}}\n",
      "            leaf_left = 0.975\n",
      "            leaf_right = 0.0\n",
      "    leaf_right = 0.1076923076923077\n",
      "{'feature': 'variance', 'split_value': np.float64(0.320165), 'left': {'feature': 'skewness', 'split_value': np.float64(5.86535), 'left': {'feature': 'curtosis', 'split_value': np.float64(6.21865), 'left': {'leaf_left': 0.9945205479452055}, 'right': {'leaf_right': 0.8397435897435898}}, 'right': {'feature': 'variance', 'split_value': np.float64(-3.4448999999999996), 'left': {'leaf_left': 0.975}, 'right': {'leaf_right': 0.0}}}, 'right': {'leaf_right': 0.1076923076923077}}\n",
      "5\n",
      "2.916956445381103\n"
     ]
    }
   ],
   "source": [
    "obj_1 = MyTreeClf(3, 2, 5)\n",
    "obj_1.fit(X, y)\n",
    "obj_1.print_tree(obj_1.tree)\n",
    "print(obj_1.tree)\n",
    "print(obj_1.leafs_cnt)\n",
    "print(obj_1.leafs_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance <= -0.10864999999999991\n",
      "    skewness <= 6.2704249999999995\n",
      "        curtosis <= 1.7235\n",
      "            skewness <= 4.139049999999999\n",
      "                leaf_left = 1.0\n",
      "                leaf_right = 0.8461538461538461\n",
      "            skewness <= -0.35642499999999977\n",
      "                variance <= -1.4119474999999997\n",
      "                    leaf_left = 1.0\n",
      "                    leaf_right = 0.8541666666666666\n",
      "                leaf_right = 0.4074074074074074\n",
      "        leaf_right = 0.3333333333333333\n",
      "    variance <= 1.6263400000000001\n",
      "        curtosis <= -1.8004750000000005\n",
      "            leaf_left = 0.797752808988764\n",
      "            leaf_right = 0.1827956989247312\n",
      "        curtosis <= -1.698975\n",
      "            leaf_left = 0.05917159763313609\n",
      "            leaf_right = 0.0\n",
      "10\n",
      "5.480781359107884\n"
     ]
    }
   ],
   "source": [
    "obj_3 = MyTreeClf(5, 200, 10, 4)\n",
    "obj_3.fit(X, y)\n",
    "obj_3.print_tree(obj_3.tree)\n",
    "print(obj_3.leafs_cnt)\n",
    "print(obj_3.leafs_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance <= 1.2780400000000007\n",
      "    skewness <= 4.934189999999997\n",
      "        variance <= -0.049580000000000624\n",
      "            curtosis <= 6.692949999999999\n",
      "                curtosis <= 2.1901399999999995\n",
      "                    leaf_left = 1.0\n",
      "                    skewness <= -0.5094400000000006\n",
      "                        leaf_left = 1.0\n",
      "                        leaf_right = 0.7272727272727273\n",
      "                skewness <= -4.2987400000000004\n",
      "                    variance <= -0.6744020000000006\n",
      "                        leaf_left = 1.0\n",
      "                        leaf_right = 0.3333333333333333\n",
      "                    leaf_right = 0.0\n",
      "            curtosis <= 0.21858000000000022\n",
      "                variance <= 1.1318273\n",
      "                    leaf_left = 1.0\n",
      "                    leaf_right = 0.875\n",
      "                curtosis <= 2.3008480000000002\n",
      "                    leaf_left = 0.43478260869565216\n",
      "                    leaf_right = 0.0\n",
      "        variance <= -3.71542\n",
      "            curtosis <= 1.244285\n",
      "                leaf_left = 1.0\n",
      "                leaf_right = 0.0\n",
      "            curtosis <= -4.36146\n",
      "                leaf_left = 1.0\n",
      "                leaf_right = 0.0\n",
      "    variance <= 2.40176\n",
      "        curtosis <= -0.9984200000000003\n",
      "            skewness <= 5.450495000000001\n",
      "                leaf_left = 0.9583333333333334\n",
      "                leaf_right = 0.0\n",
      "            leaf_right = 0.0\n",
      "        leaf_right = 0.0\n",
      "18\n",
      "9.328722002635047\n"
     ]
    }
   ],
   "source": [
    "obj_4 = MyTreeClf(10, 40, 21, 10)\n",
    "obj_4.fit(X, y)\n",
    "obj_4.print_tree(obj_4.tree)\n",
    "print(obj_4.leafs_cnt)\n",
    "print(obj_4.leafs_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance <= -0.10864999999999903\n",
      "    skewness <= 8.497483333333335\n",
      "        variance <= -2.3243400000000003\n",
      "            variance <= -3.0628666666666664\n",
      "                leaf_left = 1.0\n",
      "                skewness <= 1.5516000000000023\n",
      "                    leaf_left = 1.0\n",
      "                    leaf_right = 0.9473684210526315\n",
      "            skewness <= 5.181099999999999\n",
      "                curtosis <= 5.586333333333334\n",
      "                    variance <= -0.4844833333333336\n",
      "                        leaf_left = 1.0\n",
      "                        curtosis <= 2.0558333333333327\n",
      "                            leaf_left = 1.0\n",
      "                            leaf_right = 0.6\n",
      "                    skewness <= -4.4252\n",
      "                        entropy <= -1.3625\n",
      "                            leaf_left = 0.5\n",
      "                            leaf_right = 1.0\n",
      "                        leaf_right = 0.0\n",
      "                leaf_right = 0.0\n",
      "        variance <= -4.735386666666667\n",
      "            leaf_left = 1.0\n",
      "            leaf_right = 0.0\n",
      "    variance <= 2.203946666666667\n",
      "        curtosis <= -2.9623500000000003\n",
      "            skewness <= 5.52805\n",
      "                leaf_left = 1.0\n",
      "                leaf_right = 0.0\n",
      "            skewness <= 2.11895\n",
      "                curtosis <= 2.84915\n",
      "                    curtosis <= -0.0743999999999998\n",
      "                        leaf_left = 1.0\n",
      "                        entropy <= -0.006480000000000041\n",
      "                            leaf_left = 0.0\n",
      "                            leaf_right = 0.8\n",
      "                    leaf_right = 0.0\n",
      "                variance <= 0.31554583333333325\n",
      "                    skewness <= 3.6302333333333334\n",
      "                        leaf_left = 1.0\n",
      "                        leaf_right = 0.0\n",
      "                    leaf_right = 0.0\n",
      "        variance <= 2.9783833333333334\n",
      "            variance <= 2.4641333333333333\n",
      "                curtosis <= -2.7538833333333335\n",
      "                    leaf_left = 0.16666666666666666\n",
      "                    leaf_right = 0.0\n",
      "                leaf_right = 0.0\n",
      "            leaf_right = 0.0\n",
      "25\n",
      "12.014035087719298\n"
     ]
    }
   ],
   "source": [
    "obj_5 = MyTreeClf(15, 20, 30, 6)\n",
    "obj_5.fit(X, y)\n",
    "obj_5.print_tree(obj_5.tree)\n",
    "\n",
    "print(obj_5.leafs_cnt)\n",
    "print(obj_5.leafs_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj.leafs_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
